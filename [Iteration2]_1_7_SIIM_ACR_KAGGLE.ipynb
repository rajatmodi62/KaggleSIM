{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Iteration2] 1-7 SIIM-ACR KAGGLE",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajatmodi62/KaggleSIM/blob/master/%5BIteration2%5D_1_7_SIIM_ACR_KAGGLE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C51NDpWtAvhI",
        "colab_type": "code",
        "outputId": "c45057ce-030b-42cb-8654-1aa366b7fbb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H9RhPCGBXuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/'.kaggle'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgnWtvZnBb8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp '/content/gdrive/My Drive/kaggletoken/kaggle.json' ~/'.kaggle'/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqn8FoRgCAz9",
        "colab_type": "code",
        "outputId": "e5e2e0b3-0e6f-4a5a-da3f-c302756ae87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!kaggle datasets download abhishek/siim-png-images"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading siim-png-images.zip to /content\n",
            "100% 4.49G/4.50G [00:50<00:00, 95.8MB/s]\n",
            "100% 4.50G/4.50G [00:50<00:00, 96.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuGsHWslJYmg",
        "colab_type": "code",
        "outputId": "f511fa94-6033-4fdc-8e9b-f22830350e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!kaggle datasets download jesperdramsch/siim-acr-pneumothorax-segmentation-data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading siim-acr-pneumothorax-segmentation-data.zip to /content\n",
            " 99% 1.51G/1.52G [00:17<00:00, 53.5MB/s]\n",
            "100% 1.52G/1.52G [00:17<00:00, 94.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iVaLkQIfaMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "c60d1130-1a05-469a-a2a6-d91591bf830c"
      },
      "source": [
        "!kaggle competitions download -c siim-acr-pneumothorax-segmentation"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading download_images.py to /content\n",
            "\r  0% 0.00/3.61k [00:00<?, ?B/s]\n",
            "100% 3.61k/3.61k [00:00<00:00, 3.02MB/s]\n",
            "Downloading mask_functions.py to /content\n",
            "  0% 0.00/1.19k [00:00<?, ?B/s]\n",
            "100% 1.19k/1.19k [00:00<00:00, 1.07MB/s]\n",
            "Downloading sample%20images.zip to /content\n",
            "  0% 0.00/1.29M [00:00<?, ?B/s]\n",
            "100% 1.29M/1.29M [00:00<00:00, 86.1MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/83.8k [00:00<?, ?B/s]\n",
            "100% 83.8k/83.8k [00:00<00:00, 73.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cpPhoLGySnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q  siim-acr-pneumothorax-segmentation-data.zip -d siim-acr-pneumothorax-segmentation-data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqzAxUPACIro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q siim-png-images.zip -d siim-png-images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5VGa7LCDVGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "def dice_loss(input, target):\n",
        "    \"\"\"\n",
        "    input is a torch variable of size BatchxchannelsxHxW representing log probabilities for each class\n",
        "    target is a 1-hot representation of the groundtruth, shoud have same size as the input\n",
        "    \"\"\"\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnzaExIFN6B6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#utility functions\n",
        "#dimensions X_train->[1,1024,1024]\n",
        "def plot_data(epoch,iteration,X_train,Y_train,Y_pred):\n",
        "\n",
        "  num_img=3\n",
        "  figure, axis = plt.subplots(nrows=1, ncols=num_img, sharey=True, figsize=(num_img*10,10))\n",
        "  axis[0].set_title('Train Example')\n",
        "  axis[1].set_title('Ground Truth')\n",
        "  axis[2].set_title('Predicted Sample')\n",
        "  axis[0].imshow(X_train[0][0].cpu().numpy(),cmap=plt.cm.bone)\n",
        "  axis[1].imshow(Y_train[0][0].cpu().numpy())\n",
        "  axis[2].imshow(Y_pred[0][0].cpu().numpy())\n",
        "  title=\"Epoch :\" +str(epoch)+ \"Iteration :\"+ str(iteration)\n",
        "  figure.suptitle(title, fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfFWW-5RD1Ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torchvision.transforms as transform\n",
        "from PIL import Image, ImageFile\n",
        "from collections import defaultdict, deque\n",
        "import collections\n",
        "from tqdm import tqdm\n",
        "\n",
        "'''train- img_path, mask_csv_path'''\n",
        "'''test - img_path, mask_csv_path none'''\n",
        "class customDataLoader(Dataset):\n",
        "    \n",
        "    def rle2mask(self,rle, width, height):\n",
        "      mask= np.zeros(width* height)\n",
        "      array = np.asarray([int(x) for x in rle.split()])\n",
        "      starts = array[0::2]\n",
        "      lengths = array[1::2]\n",
        "\n",
        "      current_position = 0\n",
        "      for index, start in enumerate(starts):\n",
        "          current_position += start\n",
        "          mask[current_position:current_position+lengths[index]] = 255\n",
        "          current_position += lengths[index]\n",
        "\n",
        "      return mask.reshape(width, height)\n",
        "  \n",
        "  \n",
        "    def __init__(self, img_dir, mask_csv_path,height,width): #READ DATA\n",
        "       \n",
        "        \n",
        "        self.height=height\n",
        "        self.width=width\n",
        "        self.img_dir=img_dir\n",
        "        self.image_info = collections.defaultdict(dict)\n",
        "        \n",
        "        if mask_csv_path is not None:\n",
        "          #train case\n",
        "          self.mask_csv=pd.read_csv(mask_csv_path)\n",
        "          #print(self.mask_csv)\n",
        "          counter = 0\n",
        "          \n",
        "          for index, row in tqdm(self.mask_csv.iterrows(), total=len(self.mask_csv)):\n",
        "              image_id = row['ImageId']\n",
        "              image_path = os.path.join(img_dir, image_id)\n",
        "              \n",
        "              if os.path.exists(image_path + '.png'):\n",
        "                self.image_info[counter][\"image_id\"] = image_id\n",
        "                self.image_info[counter][\"image_path\"] = image_path\n",
        "\n",
        "                if row[\" EncodedPixels\"].strip() != \"-1\":                  \n",
        "                  self.image_info[counter][\"annotations\"] = row[\" EncodedPixels\"].strip()\n",
        "                else:\n",
        "                  self.image_info[counter][\"annotations\"]=\"-1\" \n",
        "                counter += 1\n",
        "                \n",
        "            \n",
        "        \n",
        "    def __getitem__(self, index): # RETURN ONE ITEM ON THE INDEX\n",
        "        #read the image\n",
        "        \n",
        "        image_path=self.image_info[index][\"image_path\"]\n",
        "        img = Image.open(image_path + '.png')\n",
        "        width,height=img.size\n",
        "        img=img.resize((self.width,self.height),resample=Image.BILINEAR)\n",
        "        info=self.image_info[index]\n",
        "        \n",
        "        \n",
        "        if \"annotations\" in self.image_info[0].keys():\n",
        "          #check the annotations \n",
        "          #image was encoded into its original resoliution\n",
        "          #decode the mask, treat it as an image , resize it to new resoltion \n",
        "          if info['annotations'] !=\"-1\":\n",
        "            mask= self.rle2mask(info['annotations'],width,height)\n",
        "            #take a transpose of the mask \n",
        "            mask=Image.fromarray(mask.T)\n",
        "            mask=mask.resize((self.width,self.height),resample=Image.BILINEAR)\n",
        "\n",
        "          else: \n",
        "            mask=np.ones((self.width,self.height))\n",
        "            mask=Image.fromarray(mask)\n",
        "\n",
        "          transform_to_tensor=transform.ToTensor()\n",
        "          img=transform_to_tensor(img)\n",
        "          mask=transform_to_tensor(mask)\n",
        "\n",
        "          return (img,mask)\n",
        "        \n",
        "          \n",
        "    def __len__(self): # RETURN THE DATA LENGTH\n",
        "        return len(self.image_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpRg6vedEA-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#simple vanilla unet \n",
        "class Unet(nn.Module):\n",
        "  def __init__(self,channels,height,width):\n",
        "    super(Unet, self).__init__()\n",
        "    self.nc=channels\n",
        "    self.h=height\n",
        "    self.w=width\n",
        "    self.conv11=nn.Conv2d(self.nc,8,kernel_size=3,padding=1)\n",
        "    self.conv12=nn.Conv2d(8,8,kernel_size=3,padding=1)\n",
        "    \n",
        "    self.conv21=nn.Conv2d(8,16,kernel_size=3,padding=1)\n",
        "    self.conv22=nn.Conv2d(16,16,kernel_size=3,padding=1)\n",
        "    \n",
        "    self.conv31=nn.Conv2d(16,32,kernel_size=3,padding=1)\n",
        "    self.conv32=nn.Conv2d(32,32,kernel_size=3,padding=1)\n",
        "    \n",
        "    self.conv41=nn.Conv2d(32,64,kernel_size=3,padding=1)\n",
        "    self.conv42=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
        "    \n",
        "    \n",
        "    self.conv51=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
        "    self.conv52=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
        "    \n",
        "    self.conv61=nn.Conv2d(64,128,kernel_size=3,padding=1)\n",
        "    self.conv62=nn.Conv2d(128,128,kernel_size=3,padding=1)\n",
        "    self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "    \n",
        "    #upsampling network , increate the number of layers, concat, and get the outputs\n",
        "    self.upconv1=nn.ConvTranspose2d(128,64,kernel_size=2,stride=2)\n",
        "    \n",
        "    self.conv71=nn.Conv2d(128,64,kernel_size=3,padding=1)\n",
        "    self.conv72=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
        "    \n",
        "    self.upconv2=nn.ConvTranspose2d(64,32,kernel_size=2,stride=2)\n",
        "    \n",
        "    self.conv81=nn.Conv2d(96,64,kernel_size=3,padding=1)\n",
        "    self.conv82=nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
        "    \n",
        "    self.conv91=nn.Conv2d(64,32,kernel_size=3,padding=1)\n",
        "    self.conv92=nn.Conv2d(32,32,kernel_size=3,padding=1)\n",
        "    \n",
        "    self.upconv3=nn.ConvTranspose2d(32,16,kernel_size=2,stride=2)\n",
        "    self.conv10_1=nn.Conv2d(32,16,kernel_size=3,padding=1)\n",
        "    self.conv10_2=nn.Conv2d(16,16,kernel_size=3,padding=1)\n",
        "    \n",
        "    self.upconv4=nn.ConvTranspose2d(16,8,kernel_size=2,stride=2)\n",
        "    self.conv11_1=nn.Conv2d(16,8,kernel_size=3,padding=1)\n",
        "    self.conv11_2=nn.Conv2d(8,8,kernel_size=3,padding=1)\n",
        "    \n",
        "    self.finalconv=nn.Conv2d(8,1,kernel_size=1)\n",
        "\n",
        "        \n",
        "  def forward(self,input):\n",
        "    c1=F.relu(self.conv11(input))\n",
        "    c1=F.relu(self.conv12(c1))\n",
        "    p1=self.pool(c1)\n",
        "    #8X64X64 \n",
        "    \n",
        "    c2=F.relu(self.conv21(p1))\n",
        "    c2=F.relu(self.conv22(c2))\n",
        "    p2=self.pool(c2)\n",
        "    #16x32x32\n",
        "    \n",
        "    c3=F.relu(self.conv31(p2))\n",
        "    c3=F.relu(self.conv32(c3))\n",
        "    p3=self.pool(c3)\n",
        "    #32X16X16\n",
        "    \n",
        "    c4=F.relu(self.conv41(p3))\n",
        "    c4=F.relu(self.conv42(c4))\n",
        "    p4=self.pool(c4)\n",
        "   \n",
        "    #64X8X8\n",
        "    c5=F.relu(self.conv51(p4))\n",
        "    c5=F.relu(self.conv52(c5))\n",
        "    p5=self.pool(c5)\n",
        "    \n",
        "    #64X64X4\n",
        "    c55=F.relu(self.conv61(p5))\n",
        "    c55=F.relu(self.conv62(c55))\n",
        "    \n",
        "    #128X4X4\n",
        "    #upsampling network \n",
        "    u6=self.upconv1(c55)\n",
        "    #64X8X8\n",
        "    u6=torch.cat((u6,c5),1)\n",
        "    #128X8X8\n",
        "    c6=F.relu(self.conv71(u6))\n",
        "    c6=F.relu(self.conv72(c6))\n",
        "    \n",
        "    #64X8X8\n",
        "    u7=self.upconv2(c6)\n",
        "    u7=torch.cat((u7,c4),1)\n",
        "    #96X16X16\n",
        "    c7=F.relu(self.conv81(u7))  \n",
        "    c7=F.relu(self.conv82(c7))\n",
        "    #reduce to 64 dimensions\n",
        "    \n",
        "    u7=self.upconv2(c7)\n",
        "    u7=torch.cat((u7,c3),1)\n",
        "    c7=F.relu(self.conv91(u7))\n",
        "    c7= F.relu(self.conv92((c7)))\n",
        "    \n",
        "    u8=self.upconv3(c7)\n",
        "    u8=torch.cat((u8,c2),1)\n",
        "    c8= F.relu(self.conv10_1((u8)))\n",
        "    c8= F.relu(self.conv10_2((c8)))\n",
        "    \n",
        "    u9=self.upconv4(c8)\n",
        "    u9=torch.cat((u9,c1),1)\n",
        "    c9= F.relu(self.conv11_1((u9)))\n",
        "    c9= F.relu(self.conv11_2((c9)))\n",
        "    ##now need to concat c1\n",
        "    #print(u9.size())\n",
        "    \n",
        "    c10=torch.sigmoid(self.finalconv(c9))\n",
        "    return c10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_BYASSaEL_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.backends.cudnn\n",
        "\n",
        "def train(epoch, num_epochs, net, train_loader):\n",
        "    mean_val_loss = []\n",
        "    return mean_val_loss\n",
        "    # End of train function\n",
        "    \n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        #print(\"initialized weights\")\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiuoAyTizYYa",
        "colab_type": "code",
        "outputId": "414efaa7-e76d-44a1-d535-bae570d0621d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "print('::......STARTING SIIM SEGMENTATION ON MMWHS DATASET......::\\n\\n')\n",
        "\n",
        "########################################################################################################################\n",
        "    # DATA LOADING\n",
        "########################################################################################################################\n",
        "\n",
        "print('Building Dataset....')\n",
        "  \n",
        "# Prepare training dataset for dataloading\n",
        "train_dataloader_input=customDataLoader('/content/siim-png-images/train_png','/content/siim-acr-pneumothorax-segmentation-data/train-rle.csv',128,128)\n",
        "\n",
        " # Training Data loader (Using built in Torch class Dataset, refer to customDataLoader)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataloader_input,\n",
        "                                           batch_size=128,\n",
        "                                           shuffle=True,\n",
        "                                           ) #\n",
        "\n",
        "print('....Dataset built!')\n",
        "\n",
        "##############################################################s##########################################################\n",
        "    # SETUP NEURAL NETWORK, LOSS FUNCTION\n",
        "########################################################################################################################\n",
        "print('Initializing model...')\n",
        "num_epochs=500\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "unet= Unet(1,128,128).to(device)\n",
        "\n",
        "\n",
        " # Define loss criterion..\n",
        "  \n",
        "loss=nn.BCELoss()\n",
        "optimizer_unet=optim.Adam(unet.parameters())\n",
        "unet.apply(weights_init)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  6%|▌         | 719/11582 [00:00<00:01, 7186.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "::......STARTING SIIM SEGMENTATION ON MMWHS DATASET......::\n",
            "\n",
            "\n",
            "Building Dataset....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11582/11582 [00:01<00:00, 7581.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "....Dataset built!\n",
            "Initializing model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unet(\n",
              "  (conv11): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv12): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv21): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv22): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv31): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv32): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv41): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv42): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv51): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv52): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv61): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv62): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (upconv1): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (conv71): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv72): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (upconv2): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (conv81): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv82): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv91): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv92): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (upconv3): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (conv10_1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv10_2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (upconv4): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (conv11_1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv11_2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (finalconv): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HjkA444Ot4D",
        "colab_type": "code",
        "outputId": "beb9333f-3948-4d3d-ad45-08e3e74d2bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "########################################################################################################################\n",
        "    # PERFORM NETWORK TRAINING AND SAVE LOSS DATA\n",
        "########################################################################################################################\n",
        "\n",
        "print('\\n===============================TRAINING BEGINS===============================')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  \n",
        "  running_loss=0\n",
        "  \n",
        "  for i,(img,mask) in enumerate(train_loader):\n",
        "    \n",
        "    #print(img.size())\n",
        "    img=img.to(device,dtype=torch.float)\n",
        "    mask=mask.to(device,dtype=torch.float)\n",
        "    mask=mask/255\n",
        "    #print(img.size())\n",
        "    unet.zero_grad()\n",
        "    output_mask=unet(img)\n",
        "    error=loss(output_mask,mask)\n",
        "    error.backward()\n",
        "    optimizer_unet.step()\n",
        "    #output_mask=output_mask>=0.5\n",
        "#     with torch.no_grad():\n",
        "#       print(\"1\",np.max(output_mask.cpu().numpy()))\n",
        "#       print(\"2\",np.mean(mask.cpu().numpy()))\n",
        "      #print(\"gradients\",list(unet.parameters()))\n",
        "    running_loss+=error.item()\n",
        "    if i%10==0:\n",
        "      print('epoch:[%d], iteration:[%d], loss: %f' %\n",
        "              (epoch + 1,  i, running_loss / 10))\n",
        "      running_loss=0\n",
        "    #remove later\n",
        "    torch.save({\n",
        "          'epoch': epoch,\n",
        "          'model_state_dict': unet.state_dict(),\n",
        "          'optimizer_state_dict': optimizer_unet.state_dict(),\n",
        "          'loss': running_loss,\n",
        "          }, \"checkpoint.pth\")  \n",
        "        #plot_data(epoch,i,img,mask,output_mask)\n",
        "  print('\\n===============================SAVING WEIGHTS=============================')   \n",
        "  torch.save({\n",
        "          'epoch': epoch,\n",
        "          'model_state_dict': unet.state_dict(),\n",
        "          'optimizer_state_dict': optimizer_unet.state_dict(),\n",
        "          'loss': running_loss,\n",
        "          }, \"checkpoint.pth\")\n",
        "print('\\n===============================TRAINING COMPLETE=============================')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===============================TRAINING BEGINS===============================\n",
            "epoch:[1], iteration:[0], loss: 0.069478\n",
            "epoch:[1], iteration:[10], loss: 0.689561\n",
            "epoch:[1], iteration:[20], loss: 0.670219\n",
            "epoch:[1], iteration:[30], loss: 0.490455\n",
            "epoch:[1], iteration:[40], loss: 0.241129\n",
            "epoch:[1], iteration:[50], loss: 0.410600\n",
            "epoch:[1], iteration:[60], loss: 0.331944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EOc7TLgLD17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e74f40f3-002e-4e87-b498-447dec897db1"
      },
      "source": [
        "torch.cuda.max_memory_allocated(device=None)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1832665088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9lvIXW7CNYZ",
        "colab_type": "code",
        "outputId": "369387fc-6e00-44b0-ed3e-9132eed5b9ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print('====================TESTING SIIM SEGMENTATION====================')\n",
        "print('Initializing Neural Network........................')\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# change processing device to gpu\n",
        "unet= Unet(1,128,128).to(device)\n",
        "unet.eval()\n",
        "\n",
        "\n",
        "\n",
        "# Load old weights\n",
        "checkpoint = torch.load('checkpoint.pth')\n",
        "unet.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "print('....dummyUnet Network loaded with weights')\n",
        "\n",
        "\n",
        "# Build dataset for loading into network!!\n",
        "print('Building testing dataset......')\n",
        "  \n",
        "test_data_path = '/content/siim-png-images/test_png'\n",
        "\n",
        "# Prepare validation dataset for dataloading\n",
        "\n",
        "\n",
        "submission_csv=pd.read_csv('sample_submission.csv')\n",
        "\n",
        "#drop duplicates from the submission_csv\n",
        "masks_ = submission_csv.groupby('ImageId')['ImageId'].count().reset_index(name='N')\n",
        "masks_ = masks_.loc[masks_.N > 1].ImageId.values\n",
        "###\n",
        "submission_csv = submission_csv.drop_duplicates('ImageId', keep='last').reset_index(drop=True)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================TESTING SIIM SEGMENTATION====================\n",
            "Initializing Neural Network........................\n",
            "....dummyUnet Network loaded with weights\n",
            "Building testing dataset......\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rLur4msg9KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Testing Data loader (Using built in Torch class Dataset, refer to dataset.py)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataloader_input,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=True,\n",
        "                                          pin_memory=True,\n",
        "                                          num_workers=4)  \n",
        "print('...............Dataset Built!')\n",
        "print('===============================TESTING BEGINS===============================')\n",
        "\n",
        "mkdir('result')\n",
        "copyfile('../input/siim-acr-pneumothorax-segmentation/sample_submission.csv', './result/sample_result.csv')\n",
        "\n",
        "print('===============================TESTING COMPLETE===============================')\n",
        "print('segmentation result is saved into ./result/sample_result.csv ')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C3K4sHdfwRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "394629ea-81c1-46cd-dd7e-119d74a2fddb"
      },
      "source": [
        "submission_csv.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.2.276.0.7230010.3.1.4.8323329.6567.151787519...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.2.276.0.7230010.3.1.4.8323329.6170.151787519...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.2.276.0.7230010.3.1.4.8323329.6346.151787519...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.2.276.0.7230010.3.1.4.8323329.6890.151787520...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.2.276.0.7230010.3.1.4.8323329.6400.151787519...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             ImageId  EncodedPixels\n",
              "0  1.2.276.0.7230010.3.1.4.8323329.6567.151787519...             -1\n",
              "1  1.2.276.0.7230010.3.1.4.8323329.6170.151787519...             -1\n",
              "2  1.2.276.0.7230010.3.1.4.8323329.6346.151787519...             -1\n",
              "3  1.2.276.0.7230010.3.1.4.8323329.6890.151787520...             -1\n",
              "4  1.2.276.0.7230010.3.1.4.8323329.6400.151787519...             -1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN99AmXFg4je",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86263489-5c58-4522-c1f9-4b2b8f341cda"
      },
      "source": [
        "def mask2rle(img, width, height):\n",
        "  rle = []\n",
        "  lastColor = 0;\n",
        "  currentPixel = 0;\n",
        "  runStart = -1;\n",
        "  runLength = 0;\n",
        "\n",
        "  for x in range(width):\n",
        "      for y in range(height):\n",
        "          currentColor = img[x][y]\n",
        "          if currentColor != lastColor:\n",
        "              if currentColor == 255:\n",
        "                  runStart = currentPixel;\n",
        "                  runLength = 1;\n",
        "              else:\n",
        "                  rle.append(str(runStart));\n",
        "                  rle.append(str(runLength));\n",
        "                  runStart = -1;\n",
        "                  runLength = 0;\n",
        "                  currentPixel = 0;\n",
        "          elif runStart > -1:\n",
        "              runLength += 1\n",
        "          lastColor = currentColor;\n",
        "          currentPixel+=1;\n",
        "\n",
        "  return \" \".join(rle)\n",
        "\n",
        "transform_to_tensor=transform.ToTensor()\n",
        "\n",
        "test_image_height=128\n",
        "test_image_width=128\n",
        "threshold=127\n",
        "sublist=[]\n",
        "\n",
        "for index, row in tqdm(submission_csv.iterrows(),total=len(submission_csv)):\n",
        "  image_id=row['ImageId']\n",
        "  if image_id in list(masks_.ImageId):\n",
        "    img_path = os.path.join('/content/siim-png-images/test_png', image_id + '.png')\n",
        "    img = Image.open(img_path)\n",
        "    width, height = img.size\n",
        "    img = img.resize((test_image_height, test_image_width), resample=Image.BILINEAR)\n",
        "    img=transform_to_tensor(img)\n",
        "    img=img.unsqueeze_(0)\n",
        "    result = unet(img.to(device))\n",
        "    #transform the result to pil image, resize to width and height,\n",
        "    result=transform.ToPILImage()(result.cpu().detach()[0])\n",
        "    result = np.asarray(result.resize((width, height), resample=Image.BILINEAR))\n",
        "    result=(result*255>threshold).astype(np.uint8).T\n",
        "    #print(result)\n",
        "    #if any ones is there, then segmentaion found \n",
        "    \n",
        "    if np.max(result)==1:\n",
        "      rle=mask2rle(result,width,height)\n",
        "      print(rle)\n",
        "      sublist.append([image_id,rle])\n",
        "    else:\n",
        "      rle='-1'\n",
        "      sublist.append([image_id,rle])\n",
        "\n",
        "#create a submission_csv\n",
        "submission_df = pd.DataFrame(sublist, columns=submission_csv.columns.values)\n",
        "submission_df.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 80%|███████▉  | 1093/1372 [00:27<00:07, 38.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 80%|███████▉  | 1097/1372 [00:27<00:07, 39.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 80%|████████  | 1101/1372 [00:27<00:06, 39.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 81%|████████  | 1105/1372 [00:27<00:06, 39.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 81%|████████  | 1110/1372 [00:27<00:06, 39.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 81%|████████  | 1114/1372 [00:27<00:06, 39.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 81%|████████▏ | 1118/1372 [00:27<00:06, 39.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 82%|████████▏ | 1122/1372 [00:27<00:06, 39.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 82%|████████▏ | 1127/1372 [00:27<00:06, 39.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 1132/1372 [00:28<00:05, 40.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 1137/1372 [00:28<00:05, 39.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 1142/1372 [00:28<00:05, 40.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 84%|████████▎ | 1147/1372 [00:28<00:05, 39.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 84%|████████▍ | 1152/1372 [00:28<00:05, 40.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 84%|████████▍ | 1157/1372 [00:28<00:05, 40.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 85%|████████▍ | 1162/1372 [00:28<00:05, 40.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 85%|████████▌ | 1167/1372 [00:28<00:05, 40.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 85%|████████▌ | 1172/1372 [00:29<00:04, 40.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 86%|████████▌ | 1177/1372 [00:29<00:04, 40.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 86%|████████▌ | 1182/1372 [00:29<00:04, 40.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 87%|████████▋ | 1187/1372 [00:29<00:04, 40.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 87%|████████▋ | 1192/1372 [00:29<00:04, 40.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 87%|████████▋ | 1197/1372 [00:29<00:04, 40.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 88%|████████▊ | 1202/1372 [00:29<00:04, 40.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 88%|████████▊ | 1207/1372 [00:29<00:04, 40.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 88%|████████▊ | 1212/1372 [00:30<00:03, 40.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 89%|████████▊ | 1217/1372 [00:30<00:03, 40.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 89%|████████▉ | 1222/1372 [00:30<00:03, 39.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 89%|████████▉ | 1226/1372 [00:30<00:03, 39.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 90%|████████▉ | 1230/1372 [00:30<00:03, 39.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 90%|████████▉ | 1234/1372 [00:30<00:03, 38.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 90%|█████████ | 1238/1372 [00:30<00:03, 38.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1242/1372 [00:30<00:03, 39.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1246/1372 [00:30<00:03, 39.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 91%|█████████ | 1251/1372 [00:31<00:03, 39.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 1256/1372 [00:31<00:02, 39.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 1260/1372 [00:31<00:02, 39.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 1264/1372 [00:31<00:02, 39.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 1269/1372 [00:31<00:02, 39.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 1273/1372 [00:31<00:02, 39.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 1277/1372 [00:31<00:02, 39.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 1282/1372 [00:31<00:02, 39.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▎| 1286/1372 [00:31<00:02, 39.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 1291/1372 [00:32<00:02, 40.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 1296/1372 [00:32<00:01, 39.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▍| 1301/1372 [00:32<00:01, 39.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 1305/1372 [00:32<00:01, 39.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 95%|█████████▌| 1309/1372 [00:32<00:01, 39.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 1314/1372 [00:32<00:01, 39.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 1318/1372 [00:32<00:01, 39.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▋| 1322/1372 [00:32<00:01, 39.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 1327/1372 [00:33<00:01, 39.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 1332/1372 [00:33<00:00, 40.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 1337/1372 [00:33<00:00, 39.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 1341/1372 [00:33<00:00, 39.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 1346/1372 [00:33<00:00, 40.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 1351/1372 [00:33<00:00, 40.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 1356/1372 [00:33<00:00, 39.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 1360/1372 [00:33<00:00, 38.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 99%|█████████▉| 1364/1372 [00:33<00:00, 38.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|█████████▉| 1369/1372 [00:34<00:00, 39.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1372/1372 [00:34<00:00, 40.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skxxeyot5WFb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "342f9321-b5d2-4254-dd74-f2e50450206a"
      },
      "source": [
        "!kaggle competitions submit -f submission.csv -m \"my submission\" siim-acr-pneumothorax-segmentation "
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 77.5k/77.5k [00:01<00:00, 41.2kB/s]\n",
            "Successfully submitted to SIIM-ACR Pneumothorax Segmentation"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCPkZQog6Bei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "137e84d6-b680-4ca1-8e51-8e0168ece0de"
      },
      "source": [
        "!kaggle competitions list"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ref                                                deadline             category            reward  teamCount  userHasEntered  \n",
            "-------------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "digit-recognizer                                   2030-01-01 00:00:00  Getting Started  Knowledge       3118            True  \n",
            "titanic                                            2030-01-01 00:00:00  Getting Started  Knowledge      11527            True  \n",
            "house-prices-advanced-regression-techniques        2030-01-01 00:00:00  Getting Started  Knowledge       4495            True  \n",
            "imagenet-object-localization-challenge             2029-12-31 07:00:00  Research         Knowledge         46            True  \n",
            "competitive-data-science-predict-future-sales      2019-12-31 23:59:00  Playground           Kudos       3595            True  \n",
            "open-images-2019-object-detection                  2019-10-01 23:59:00  Research           $25,000        186            True  \n",
            "open-images-2019-visual-relationship               2019-10-01 23:59:00  Research           $25,000         67           False  \n",
            "recursion-cellular-image-classification            2019-09-26 23:59:00  Research           $13,000        292           False  \n",
            "youtube8m-2019                                     2019-09-13 23:59:00  Research           $25,000         51           False  \n",
            "aptos2019-blindness-detection                      2019-09-05 23:59:00  Featured           $50,000        715           False  \n",
            "siim-acr-pneumothorax-segmentation                 2019-09-04 23:59:00  Featured           $30,000        770            True  \n",
            "champs-scalar-coupling                             2019-08-28 23:59:00  Featured           $30,000       1616           False  \n",
            "generative-dog-images                              2019-08-09 23:59:00  Research           $10,000        280           False  \n",
            "two-sigma-financial-news                           2019-08-05 23:59:00  Featured          $100,000       2927           False  \n",
            "recognizing-faces-in-the-wild                      2019-08-01 23:59:00  Playground       Knowledge        417           False  \n",
            "jigsaw-unintended-bias-in-toxicity-classification  2019-07-10 23:59:00  Featured           $65,000       3167            True  \n",
            "aerial-cactus-identification                       2019-07-08 23:59:00  Playground       Knowledge       1168           False  \n",
            "data-science-for-good-city-of-los-angeles          2019-06-21 23:59:00  Analytics          $15,000          0           False  \n",
            "instant-gratification                              2019-06-20 23:59:00  Featured            $5,000       1836           False  \n",
            "freesound-audio-tagging-2019                       2019-06-17 22:22:00  Research            $5,000        880           False  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93iXwq_W6LV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d75d1077-7910-4a33-84b0-756b731b9015"
      },
      "source": [
        "!kaggle  competitions submit siim-acr-pneumothorax-segmentation "
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: kaggle competitions [-h]\n",
            "                           {list,files,download,submit,submissions,leaderboard}\n",
            "                           ...\n",
            "kaggle competitions: error: too few arguments\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdhwgE3A6O6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}